#!/usr/bin/python
# Copyright (C) 2011 Red Hat, Inc.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# funfin = Function Fingerprint
import pyfaf
import logging
import itertools
import heapq
import shelve

class PrioQueue(object):
    def __init__(self):
        self.h = []

    def empty(self):
        return len(self.h) == 0

    def push(self, item, prio):
        heapq.heappush(self.h, (prio, item))

    def pop(self):
        return heapq.heappop(self.h)

    def __len__(self):
        return len(self.h)

# Command line argument processing
cmdline_parser = pyfaf.argparse.ArgumentParser(description="Report on funfin.")
cmdline_parser.add_argument("--state", default=None, metavar="FILE", help="Use FILE for persistent state")
cmdline_args = cmdline_parser.parse_args()


# Load database and bugs
logging.debug("Connecting to DB.")
db = pyfaf.cache.Database()

# Find multiple builds of same component.
def prepare_clusters():
    db.execute("SELECT id FROM fedora_koji_build_funfin_report")
    report_ids = {i[0] for i in db.fetchall()}

    clusters = PrioQueue()
    logging.info("Preparing clusters.")
    while any(report_ids):
        current_id = report_ids.pop()
        db.execute("SELECT name FROM fedora_koji_build WHERE id = ?", [current_id])

        try:
            name = db.fetchall()[0][0]
        except IndexError:
            logging.warning("Build not available: {0}".format(current_id))
            continue

        query = """SELECT r.id FROM fedora_koji_build_funfin_report r
                       JOIN fedora_koji_build b ON r.id = b.id
                       WHERE b.name=?"""
        db.execute(query, [name])
        cluster = {i[0] for i in db.fetchall()}
        if len(cluster) == 0:
            logging.error("Failed to find {0} in fedora_koji_build table.".format(name))
            exit(1)
        report_ids -= cluster
        clusters.push(cluster, -1)

    return clusters

if cmdline_args.state:
    state = shelve.open(cmdline_args.state)
else:
    state = dict()

if state.has_key('clusters'):
    logging.info("Loading clusters from saved state")
    clusters = state['clusters']
else:
    clusters = prepare_clusters()
    if cmdline_args.state:
        state['clusters'] = clusters
        state.sync()
        logging.info("Clusters saved")
    else:
        logging.info("Not saving clusters")

class BinaryDupsEvaluation:
    def __init__(self):
        # Which RPM this is.
        self.rpm_id = None
        # Which binary (abs path) is this.
        self.binary = None
        # List of (symbolA, symbolB, symbolC) duplicates from the binary.
        self.duplicates = []
        # Number of all symbols in that binary.
        self.symbol_count = 0

class CrossBinaryEvaluation:
    def __init__(self):
        self.rpm_id_a = None
        self.rpm_id_b = None
        self.crossArch = None
        # Which binary (abs path) is this.
        self.binary = None
        # Number of symbols that matched between the binaries.
        self.matched_count = 0
        # Number of symbols present in just one of the binaries.
        self.not_found_count = 0
        # Names of symbols that differ between the binaries.
        self.unmatched = []

    def __str__(self):
        return "{0}: matched {1}, unmatched {2}, not found {3}".format(self.binary, self.matched_count, len(self.unmatched), self.not_found_count)

def get_fingerprint(fingerprint_parts, report_function):
    return "".join([report_function.__dict__[part] for part in fingerprint_parts])

class Fingerprint:
    def __init__(self, parts):
        # Names of metrics, such as "fp_library_function_calls".
        self.parts = parts
        self.dupsEvaluations = []
        self.crossEvaluations = []

    def add_binary_dups_evaluation(self, report, functioncount, fingerprintindex, fingerprintcount):
        """
        functioncount, fingerprintindex, fingerprintcount - only for logging
        """
        functionindex = (fingerprintindex - 1) * functioncount
        for rpm in report.rpms:
            for binary in rpm.binaries:
                e = BinaryDupsEvaluation()
                e.rpm_id = rpm.id
                e.binary = binary.id
                e.symbol_count = len(binary.functions)
                d = {}
                for fun in binary.functions:
                    functionindex += 1
                    if functionindex % 1000000 == 0:
                        logging.debug("    - {0}/{1} checks processed".format(functionindex, functioncount * fingerprintcount))

                    fingerprint = get_fingerprint(self.parts, fun)
                    if fingerprint in d:
                        #logging.debug("Duplicate fingerprint: {0}".format(fingerprint))
                        d[fingerprint].append(fun)
                    else:
                        #logging.debug("New fingerprint: {0}".format(fingerprint))
                        d[fingerprint] = [fun]

                for fingerprint, funs in d.items():
                    if len(funs) > 1:
                        #logging.debug("APPENDING TO DUPLICATES: {0}".format([fun.symbol for fun in funs]))
                        e.duplicates.append([fun.symbol for fun in funs])
                self.dupsEvaluations.append(e)

    def add_cross_binary_evaluation(self, report1, report2):
        for rpm1 in report1.rpms:
            for binary1 in rpm1.binaries:
                for rpm2 in report2.rpms:
                    if rpm1 == rpm2:
                        continue

                    for binary2 in rpm2.binaries:
                        if binary1.id != binary2.id and binary1.id != binary2.id.replace("/lib64/", "/lib/"):
                            continue

                        e = CrossBinaryEvaluation()
                        e.rpm_id_a = rpm1.id
                        e.rpm_id_b = rpm2.id
                        e.binary = binary1.id
                        e.crossArch = rpm1.architecture != rpm2.architecture
                        not_found = {f.symbol for f in binary1.functions} ^ {f.symbol for f in binary2.functions}
                        e.not_found_count = len(not_found)

                        for fun1 in binary1.functions:
                            for fun2 in binary2.functions:
                                if fun1.symbol != fun2.symbol:
                                    continue

                                f1 = get_fingerprint(self.parts, fun1)
                                f2 = get_fingerprint(self.parts, fun2)
                                if f1 == f2:
                                    e.matched_count += 1
                                else:
                                    e.unmatched.append(fun1.symbol)
                                break

                        # DEBUG
                        #print "{0} EQUALS {1}".format(binary1.id, binary2.id)
                        #print "matched {0}, unmatched {1}, not found {2}".format(e.matched_count, len(e.unmatched), e.not_found_count)
                        #print "ONLY PRESENT IN A ", rpm1.architecture, not_found - {f.symbol for f in binary2.functions}
                        #print "ONLY PRESENT IN B", rpm2.architecture, not_found - {f.symbol for f in binary1.functions}
                        #logging.debug("  - adding cross evaluation: {0}".format(e))
                        self.crossEvaluations.append(e)

    def update_success_rates(self):
        """
        1 = 100% success, no duplicates
        """
        dup_allsyms = 0
        dup_dupsyms = 0
        for e in self.dupsEvaluations:
            dup_allsyms += e.symbol_count
            dup_dupsyms += reduce(lambda a,d: a + len(d), e.duplicates, 0)

        self.success_rate = 0
        self.success_rate_count = 0

        if dup_allsyms > 0:
            self.dup_success_rate = 1.0 - (dup_dupsyms / float(dup_allsyms))
            self.success_rate_count += 1
            self.success_rate += self.dup_success_rate
        else:
            self.dup_success_rate = "??"

        multiarchcross_allsyms = 0
        multiarchcross_unmatchedsyms = 0
        for e in self.crossEvaluations:
            if not e.crossArch:
                continue
            multiarchcross_allsyms += e.matched_count + len(e.unmatched)
            multiarchcross_unmatchedsyms += len(e.unmatched)
        if multiarchcross_allsyms > 0:
            self.multiarchcross_success_rate = 1.0 - (multiarchcross_unmatchedsyms/float(multiarchcross_allsyms))
            self.success_rate_count += 1
            self.success_rate += self.multiarchcross_success_rate
        else:
            self.multiarchcross_success_rate = "??"

        singlearchcross_allsyms = 0
        singlearchcross_unmatchedsyms = 0
        for e in self.crossEvaluations:
            if e.crossArch:
                continue
            singlearchcross_allsyms += e.matched_count + len(e.unmatched)
            singlearchcross_unmatchedsyms += len(e.unmatched)
        if singlearchcross_allsyms > 0:
            self.singlearchcross_success_rate = 1.0 - (singlearchcross_unmatchedsyms/float(singlearchcross_allsyms))
            self.success_rate_count += 1
            self.success_rate += self.singlearchcross_success_rate
        else:
            self.singlearchcross_success_rate = "??"

        if self.success_rate_count > 0:
            self.success_rate /= self.success_rate_count

components = ["fp_library_function_calls",
              "fp_transitive_lib_calls",
              "fp_equality_jump_presence",
              "fp_unsigned_comparison_jump_presence",
              "fp_signed_comparison_jump_presence",
              "fp_andor_presence",
              "fp_shift_presence",
              "fp_simple_recursion_presence",
              "fp_unconditional_local_jump_presence",
              "fp_internal_calls"]

def powerset(iterable):
    "powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)"
    s = list(iterable)
    return itertools.chain.from_iterable(itertools.combinations(s, r) for r in range(len(s)+1))

fingerprints = []
for perm in powerset(components):
    if len(perm) == 0:
        continue
    fingerprints.append(Fingerprint(perm))

def print_report():
    for f in fingerprints:
        f.update_success_rates()

    top = sorted(fingerprints, key=lambda x: x.success_rate, reverse=True)
    top_index = 0
    print("-- Best fingerprints for both duplicates and cross success rate")
    print("-----------------------------------------------------------------")
    for f in top[:5]:
        top_index += 1
        print("{0}. {1}".format(top_index, ", ".join(f.parts)))
        print("  - duplicate success: {0:.2f}%".format(f.dup_success_rate * 100))
        value = "{0:.2f}".format(f.singlearchcross_success_rate * 100) if not isinstance(f.singlearchcross_success_rate, basestring) else f.singlearchcross_success_rate
        print("  - single arch cross build success rate: {0}%".format(value))
        value = "{0:.2f}".format(f.multiarchcross_success_rate * 100) if not isinstance(f.multiarchcross_success_rate, basestring) else f.multiarchcross_success_rate
        print("  - multi arch cross build success rate: {0}%".format(value))

index = 0
while not clusters.empty():
    (prio, cluster) = clusters.pop()
    index += 1
    build = pyfaf.run.cache_get("fedora-koji-build", list(cluster)[0])
    logging.info("[{0}/{1}] Processing {2}: {3}".format(index, len(clusters), build.name, ",".join(["#{0}".format(c) for c in cluster])))
    del build

    # DEBUG
    #if len(cluster) == 1:
    #    logging.info("  - single report, not interesting")
    #    continue

    reports = [pyfaf.run.cache_get("fedora-koji-build-funfin-report", i, failure_allowed=False) for i in cluster]
    reports = filter(lambda report: len(report.binaries()) > 0, reports)
    if len(reports) == 0:
        logging.info("  - no binaries")
        continue

    # Extend reports to include the rpm arch
    for report in reports:
        for rpm in report.rpms:
            r = pyfaf.run.cache_get("fedora-koji-rpm", rpm.id, failure_allowed=False)
            rpm.architecture = r.architecture

    # Estimate the number of combinations for cross binary evaluation, i.e. how
    # many times will the body of the innermost loop run
    functions = 0
    for binary in reports[0].binaries():
        functions += len(binary.functions)
    nreports = len(reports)
    combinations = len(fingerprints)*functions*((nreports*(nreports-1))/2)
    logging.debug("  - estimated combinations for cross binary evaluation: {0}".format(combinations))

    # Requeue the report if it would take too long to process
    if (combinations > 5000000) and prio == 0:
        logging.info("Estimated {0} combinations too much, delaying".format(combinations))
        clusters.push(cluster, combinations)
        index -= 1
        continue

    # First, do BinaryDupsEvaluation.
    logging.info("  - duplicates evaluation");
    for report in reports:
        functioncount = reduce(lambda accum, bin: accum + bin, [len(b.functions) for b in report.binaries()], 0)
        fingerprintcount = len(fingerprints)
        fingerprintindex = 0
        for fingerprint in fingerprints:
            fingerprintindex += 1
            fingerprint.add_binary_dups_evaluation(report, functioncount, fingerprintindex, fingerprintcount)

    # Second, do CrossBinaryEvaluation.
    logging.info("  - cross evaluation (self, cross arch)");
    for report in reports:
        for fingerprint in fingerprints:
            fingerprint.add_cross_binary_evaluation(report, report)

    if len(reports) > 1:
        logging.info("  - cross evaluation");
        for pair in itertools.combinations(reports, 2):
            for fingerprint in fingerprints:
                fingerprint.add_cross_binary_evaluation(pair[0], pair[1])

    print_report()
