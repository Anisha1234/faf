#!/usr/bin/python
import Queue
import collections
import logging
import multiprocessing
import os
import pyfaf
import shutil
from pyfaf import retrace

if __name__ == "__main__":
    cmdline_parser = pyfaf.argparse.ArgumentParser(
            description="Retrace unknown symbols from ureports")
    cmdline_parser.add_argument("--workers", default=multiprocessing.cpu_count(),
                                type=int, help="Use several workers to unpack")
    cmdline_parser.add_argument("--legacy", action="store_true",
                                default=False, help="Use legacy algorithm")
    cmdline = cmdline_parser.parse_args()

    db = pyfaf.storage.Database(debug=cmdline.verbose > 2)

    # old way
    if cmdline.legacy:
        retrace.retrace_symbols(db.session)
        exit(0)

    # new way
    debuginfo_map = retrace.prepare_debuginfo_map(db)
    tasks = retrace.prepare_tasks(db, debuginfo_map)

    inqueue = collections.deque(tasks)
    # max number of unpacked packages:
    # queue length (waiting in queue)
    # + workers count (waiting to push to queue)
    # + 1 (currently processing)
    outqueue = Queue.Queue(cmdline.workers)
    workers = []
    for i in xrange(cmdline.workers):
        workers.append(retrace.FafAsyncRpmUnpacker("Worker #{0}".format(i),
                                                   inqueue, outqueue))

    for worker in workers:
        logging.info("Spawning {0}".format(worker.name))
        worker.start()

    total = len(tasks)
    i = 0
    while True:
        i += 1
        wait = any([w.is_alive() for w in workers])
        try:
            task = outqueue.get(wait)
        except Queue.Empty:
            logging.info("All done!")
            break

        logging.info("[{0}/{1}] {2}".format(i, total, task["source"]["package"].nvr()))
        retrace.retrace_task(db, task)
        outqueue.task_done()
        del task

    db.session.flush()
