#!/usr/bin/python
# Copyright (C) 2012 Red Hat, Inc.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
import pyfaf
import logging
import json
import glob
import os
import datetime
from pyfaf.storage import Report, ReportRhbz, RhbzBug, ReportBtHash, ReportBacktrace

# Command line argument processing
cmdline_parser = pyfaf.argparse.ArgumentParser(description="Process reports in spool directory.")
cmdline_parser.add_argument("--spool-dir", help="Specify report spool directory",
        default=pyfaf.config.get("Report.SpoolDirectory"))
cmdline_parser.add_argument("--report", nargs="+",
        help="Save specified files instead of searching spool directory")
cmdline_args = cmdline_parser.parse_args()

if not cmdline_args.report and not cmdline_args.spool_dir:
    cmdline_parser.error("No spool directory or report specified.")

db = pyfaf.storage.Database(debug=cmdline_args.verbose > 2)

if cmdline_args.report:
    filenames = cmdline_args.report
    save_directory = None
    defer_directory = None
    attachment_directory = None
elif cmdline_args.spool_dir:
    incoming_directory = os.path.join(cmdline_args.spool_dir, "incoming")
    save_directory = os.path.join(cmdline_args.spool_dir, "saved")
    defer_directory = os.path.join(cmdline_args.spool_dir, "deferred")
    attachment_directory = os.path.join(cmdline_args.spool_dir, "attachments")

    # Create missing directories
    for d in [incoming_directory, save_directory, defer_directory]:
        if not os.path.isdir(d):
            os.makedirs(d)

    filenames = glob.glob(os.path.join(incoming_directory, "*"))
else:
    assert False

def move_file(filename, where):
    basename = os.path.basename(filename)
    target = os.path.join(where, basename)
    os.rename(filename, target)

logging.info("Processing uReports")

for i, filename in enumerate(filenames):
    with open(filename, 'r') as f:
        logging.info("[{0} / {1}] Processing report {2}.".format(i + 1, len(filenames), filename))
        db.session.begin()
        try:
            report = pyfaf.ureport.convert_to_str(json.loads(f.read()))
            report = pyfaf.ureport.validate(report)
            mtime = datetime.datetime.utcfromtimestamp(os.stat(filename).st_mtime)
            pyfaf.ureport.add_report(report, db, utctime=mtime)
        except Exception as e:
            db.session.rollback()
            logging.debug("Processing failed: {0}".format(e))
            if defer_directory:
                logging.debug("Moving report {0} to deferred directory.".format(filename))
                move_file(filename, defer_directory)
            continue

        db.session.commit()
        db.session.flush()

        if save_directory:
            logging.debug("Moving report {0} to saved directory.".format(filename))
            move_file(filename, save_directory)

if attachment_directory:
    logging.info("Processing attachments")
    # initialize bugzilla, we expect to download bugs
    bugzilla = pyfaf.bugzilla.Bugzilla(db)
    bugzilla.login()

    filenames = os.listdir(attachment_directory)
    for i, filename in enumerate(filenames):
        with open(os.path.join(attachment_directory, filename), 'r') as f:
            logging.info("[{0} / {1}] Processing attachment {2}.".format(i + 1, len(filenames), filename))
            try:
                attachment = pyfaf.ureport.convert_to_str(json.load(f))
                attachment = pyfaf.ureport.validate(attachment, checker=pyfaf.ureport.ATTACHMENT_CHECKER)
                if attachment["type"].upper() == "RHBZ":
                    report = db.session.query(Report).join(ReportBacktrace) \
                                                     .join(ReportBtHash) \
                                                     .filter(ReportBtHash.hash == attachment["bthash"]) \
                                                     .first()
                    if not report:
                        logging.debug("Report for given bthash not found")
                        continue

                    bug_id = int(attachment["data"])
                    reportbug = db.session.query(ReportRhbz).filter((ReportRhbz.report_id == report.id) &
                                                                    (ReportRhbz.rhbzbug_id == bug_id)).first()
                    if reportbug:
                        logging.debug("Skipping existing attachment")
                        continue

                    bug = db.session.query(RhbzBug).filter(RhbzBug.id == bug_id).first()
                    if not bug:
                        try:  # to download it
                            downloaded = bugzilla.download_bug(bug_id)
                            if downloaded:
                                bug = bugzilla.save_bug(downloaded)
                        except:
                            logging.error('Unable to download bug #{0}'
                                          ''.format(bug_id))

                    if bug:
                        new = ReportRhbz()
                        new.report = report
                        new.rhbzbug = bug
                        db.session.add(new)

                # flush here for best-effort
                db.session.flush()
            except Exception as ex:
                logging.error("Processing failed: {0}".format(str(ex)))
                continue

    # ToDo: get rid of the file
