#!/usr/bin/python
# Copyright (C) 2011 Red Hat, Inc.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
import koji
import pyfaf
import sys
import subprocess
import logging

def read_koji_tags(os_prefix):
    """
    Reads Koji tags from local cache.

    Arguments:
    os_prefix -- Prefix to cache target names, such as "fedora" or "rhel".

    Returns:
    A dict with tag ID as a key and pyfaf.cache.koji_tag instances as a value.
    """
    # Get koji tag list from cache
    logging.info("Loading {0}-koji-tag list from local cache.".format(os_prefix))
    koji_tag_id_list = pyfaf.run.cache_list_id("{0}-koji-tag".format(os_prefix))
    logging.info("Found {0} Koji tags in local cache.".format(len(koji_tag_id_list)))

    # Load koji tags from cache
    logging.info("Loading Koji tags from local cache.")
    koji_tags = {}
    index = 0
    for koji_tag_id in koji_tag_id_list:
        index +=1
        logging.debug("[{0}/{1}] Loading koji tag #{2}.".format(index, len(koji_tag_id_list), koji_tag_id))
        koji_tag = pyfaf.run.cache_get("{0}-koji-tag".format(os_prefix), koji_tag_id)
        koji_tags[koji_tag_id] = koji_tag
    return koji_tags

def read_koji_package_list(tag_id, koji_url_args):
    """
    Reads a list of packages that belong to certain tag from remote
    Koji server.

    Arguments:
    tag_id -- Tag identification number.
    koji_args -- List of additional faf-koji command line arguments
        such as Koji URLs.

    Returns:
    A list of package names.
    """
    logging.info("Loading Koji component list.")
    koji_args = ["faf-koji"] + koji_url_args + ["packages", "--tag-id", str(tag_id)]
    packages_text = pyfaf.run.process(koji_args, stdout=subprocess.PIPE, timeout=20, timeout_attempts=5, returncode_attempts=2)[0]
    return [package_line.split()[1] for package_line in packages_text.splitlines()]

def get_koji_tag_inheritance(tag_id, transitive):
    """
    Build inheritance list for a tag.

    Returns:
    A list of tag IDs.
    """
    tag = koji_tags[tag_id]
    result = [tag]
    for subtag in sorted(tag.inheritance, key=lambda x: x.priority, reverse=True):
        result.extend(get_koji_tag_inheritance(subtag.parent_id, not subtag.intransitive))
    return result

def find_component_in_tags(tag_list, component_name, koji_url_args):
    """
    Searchs Koji for a build of specific component that is tagged with
    one of the provided tags. Order of tags in the tag list is used to
    determine the order of searches. A list of builds from the tag
    where builds were found is returned. If there were no builds
    found, empty list is returned.
    """
    for tag in tag_list:
        # Run faf-koji list-builds several times with a timeout, because it might hung.
        logging.debug(" - searching builds in tag {0}:{1}".format(tag.id, tag.name))
        koji_args = ["faf-koji"] + koji_url_args + ["builds", str(tag.id), package]
        builds_text = pyfaf.run.process(koji_args, stdout=subprocess.PIPE, timeout=20, timeout_attempts=5, returncode_attempts=2)[0]
        builds = [builds_line.split() for builds_line in builds_text.splitlines()]
        if len(builds) > 0:
            return builds

    return []

def download_logs(build, koji_url_args):
    """
    Downloads build logs from Koji to local cache for certain build.
    """
    logging.info(" - downloading build logs for {0} {1}".format(build.id, build.name))
    for log in build.logs:
        for file in [log.build_id, log.root_id, log.state_id]:
            if file is None:
                continue

            logging.debug("   - downloading log {0}".format(file))
            cache_args = ["faf-cache", "add", "{0}-koji-build-log-data".format(cmdline_args.os_prefix), file, "--overwrite"]
            cache_proc = subprocess.Popen(cache_args, stdin=subprocess.PIPE)

            koji_args = ["faf-koji"] + koji_url_args + ["build-log", file]
            koji_proc = subprocess.Popen(koji_args, stdout=cache_proc.stdin)
            koji_proc.wait()
            if koji_proc.returncode != 0:
                sys.stderr.write("Failed to download build log from koji.\n")
                exit(1)
            cache_proc.stdin.close()
            cache_proc.wait()
            if cache_proc.returncode != 0:
                sys.stderr.write("Failed to store build log to cache.\n")
                exit(1)

def download_build_for_tags(tag_list, component_name, koji_url_args, skip_build_id_list, os_prefix):
    builds = find_component_in_tags(tag_list, component_name, koji_url_args)
    if len(builds) == 0:
        logging.info(" - no build found")
        return None

    logging.debug("    - found {0} builds".format(len(builds)))
    if int(builds[0][0]) in skip_build_id_list:
        logging.info(" - skiping build {0} already existing in local cache".format(builds[0][0]))
        return None

    logging.info(" - downloading build {0} {1}".format(builds[0][0], builds[0][1]))
    koji_args = ["faf-koji"] + koji_url_args + ["build", "--id", str(builds[0][0])]
    build_text = pyfaf.run.process(koji_args, stdout=subprocess.PIPE, timeout=15*60, timeout_attempts=5, returncode_attempts=2)[0]
    build = pyfaf.cache.koji_build.parser.from_text(build_text, failure_allowed=False)
    pyfaf.run.cache_add(build, overwrite=True, target_name="{0}-koji-build".format(os_prefix))
    download_logs(build, koji_url_args)
    return build

# Command line argument processing
cmdline_parser = pyfaf.argparse.ArgumentParser(description="Download builds from Koji.")
cmdline_parser.add_argument("os")
cmdline_parser.add_argument("tag")
cmdline_parser.add_argument("--only-missing", action="store_true", default=False, help="downloads only builds missing in the cache")
cmdline_parser.add_argument("--component", help="downloads build for a single component")
cmdline_parser.add_argument("--build-nvr", help="download one specific build by its name, version and release")
cmdline_parser.add_argument("--with-rpms", action="store_true", default=False, help="download rpm packages together with build metadata")
cmdline_parser.add_argument("--use-cache", action="store_true", default=False, help="download to cache instead of storage (deprecated)")
cmdline = cmdline_parser.parse_args()

if cmdline.use_cache:
    koji_tags = read_koji_tags(cmdline.os)
    toplevel_koji_tag = next((t for t in koji_tags.values() if t.name == cmdline.tag), None)
    if toplevel_koji_tag is None:
        sys.stderr.write("Failed to find {0} koji tag.\n".format(cmdline.tag))
        exit(1)

    tag_list = get_koji_tag_inheritance(toplevel_koji_tag.id, transitive=True)
    koji_url_args = ["--fedora"] if cmdline.os == "fedora" else ["--brew"]

    if cmdline.build_nvr is None:
        packages = read_koji_package_list(toplevel_koji_tag.id, koji_url_args)

        # If a component is specified on the command line, remove all other
        # packages (components) from the package list.
        if cmdline.component is not None:
            if cmdline.component not in packages:
                sys.stderr.write("Failed to find {0} in koji {1} tag.\n".format(cmdline.component, cmdline.tag))
                exit(1)
            packages = [cmdline.component]

        # Load build ids from local cache
        skip_build_id_list = []
        if cmdline.only_missing:
            logging.info("Loading Fedora Koji build list from local cache.")
            skip_build_id_list = pyfaf.run.cache_list_id("{0}-koji-build".format(cmdline.os))
            logging.info("Found {0} Fedora Koji builds in local cache.".format(len(skip_build_id_list)))

        # For every package, find and download the latest build.
        index = 0
        for package in sorted(packages):
            index += 1
            logging.info("[{0}/{1}] Processing package {2}.".format(index, len(packages), package))
            build = download_build_for_tags(tag_list, package, koji_url_args, skip_build_id_list, cmdline.os)
            if build and cmdline.with_rpms:
                logging.info("Downloading RPMs")
                rpms = [[rpm_id, build.id, build.nvr()] for rpm_id in build.rpms]
                i = 0
                for rpm_info in rpms:
                    i += 1
                    logging.debug("[{0}/{1}] Downloading rpm #{2} for build #{3} - {4}.".format(
                                  i, len(rpms), rpm_info[0], rpm_info[1], rpm_info[2]))
                    pyfaf.koji.download_rpm(rpm_info, cmdline.os)
    else:
        koji_args = ["faf-koji"] + koji_url_args + ["build", "--nvr", cmdline.build_nvr]
        build_text = pyfaf.run.process(koji_args, stdout=subprocess.PIPE, timeout=15*60, timeout_attempts=5, returncode_attempts=2)[0]
        build = pyfaf.cache.koji_build.parser.from_text(build_text, failure_allowed=False)
        pyfaf.run.cache_add(build, overwrite=True, target_name="{0}-koji-build".format(cmdline.os))
        download_logs(build, koji_url_args)
        if cmdline.with_rpms:
            logging.info("Downloading RPMs")
            rpms = [[rpm_id, build.id, build.nvr()] for rpm_id in build.rpms]
            index = 0
            for rpm_info in rpms:
                index += 1
                logging.debug("[{0}/{1}] Downloading rpm #{2} for build #{3} - {4}.".format(
                              index, len(rpms), rpm_info[0], rpm_info[1], rpm_info[2]))
                pyfaf.koji.download_rpm(rpm_info, cmdline.os)

    exit(0)

#storage
import rpm
import rpmUtils
import urllib2
from pyfaf.storage import *
from sqlalchemy.orm.exc import NoResultFound

LOGFILES = ["build.log", "root.log", "state.log"]

def inherit(db, tag):
    result = [tag]
    inhs = db.session.query(TagInheritance).filter(TagInheritance.tag_id == tag.id).all()
    for inh in sorted(inhs, key=lambda x: x.priority, reverse=True):
        result.extend(inherit(db, inh.parent))

    return result

def download_logs(buildarch, build, package_url):
    for logfile in LOGFILES:
        logging.debug("Saving {0} for {1}".format(logfile, arch))
        url = "{0}/{1}/{2}/{3}/data/logs/{4}/{5}".format(package_url,
                                                         build["name"],
                                                         build["version"],
                                                         build["release"],
                                                         buildarch.arch.name,
                                                         logfile)
        pipe = urllib2.urlopen(url)
        new.save_lob(logfile, pipe.fp, truncate=True, binary=False)
        pipe.close()

def download_rpm(db, rpm_info, build, package_url, build_id=None):
    arch_id = db.session.query(Arch.id).filter(Arch.name == rpm_info["arch"]).one()[0]
    new = Package()
    new.build_id = build_id
    new.name = rpm_info["name"]
    new.pkgtype = "rpm"
    new.arch_id = arch_id
    db.session.add(new)
    db.session.flush()
    pkg_id = new.id

    url = "{0}/{1}/{2}/{3}/{4}".format(package_url,
                                       build["name"],
                                       build["version"],
                                       build["release"],
                                       koji.pathinfo.rpm(rpm_info))
    pipe = urllib2.urlopen(url)
    new.save_lob("package", pipe.fp, truncate=True, binary=True)
    pipe.close()

    ts = rpm.ts()
    rpm_file = new.get_lob_fd("package")
    header = ts.hdrFromFdno(rpm_file.fileno())

    files = header.fiFromHeader()
    logging.debug("Contains {0} files".format(len(files)))
    for f in files:
        new = PackageDependency()
        new.package_id = pkg_id
        new.type = "PROVIDES"
        new.name = f[0]
        new.flags = 0
        db.session.add(new)

    provides = header.dsFromHeader('providename')
    for p in provides:
        new = PackageDependency()
        new.package_id = pkg_id
        new.type = "PROVIDES"
        new.name = p.N()
        new.flags = p.Flags()
        evr = p.EVR()
        if len(evr):
            new.epoch, new.version, new.release = rpmUtils.miscutils.stringToVersion(evr)
        db.session.add(new)

    requires = header.dsFromHeader('requirename')
    for r in requires:
        new = PackageDependency()
        new.package_id = pkg_id
        new.type = "REQUIRES"
        new.name = r.N()
        new.flags = r.Flags()
        evr = r.EVR()
        if len(evr):
            new.epoch, new.version, new.release = rpmUtils.miscutils.stringToVersion(evr)
        db.session.add(new)

    conflicts = header.dsFromHeader('conflictname')
    for c in conflicts:
        new = PackageDependency()
        new.package_id = pkg_id
        new.type = "CONFLICTS"
        new.name = c.N()
        new.flags = c.Flags()
        evr = c.EVR()
        if len(evr):
            new.epoch, new.version, new.release = rpmUtils.miscutils.stringToVersion(evr)
        db.session.add(new)

    rpm_file.close()
    db.session.flush()

db = Database(debug=cmdline.verbose > 2)

try:
    opsys = db.session.query(OpSys).filter(OpSys.name == cmdline.os).one()
except NoResultFound:
    logging.error("OS '{0}' is not supported.".format(cmdline.os))
    exit(1)

try:
    buildsys = db.session.query(BuildSystem).filter((BuildSystem.opsys_id == opsys.id) & \
                                                    (BuildSystem.xmlrpc_url != None) & \
                                                    (BuildSystem.package_url != None)).one()
except NoResultFound:
    logging.error("{0} does not support koji.".format(cmdline.os))
    exit(1)

try:
    tag = db.session.query(Tag).filter(Tag.name == cmdline.tag).one()
except NoResultFound:
    logging.error("Unable to find tag '{0}'".format(cmdline.tag))
    exit(1)

tags = inherit(db, tag)

session = koji.ClientSession(buildsys.xmlrpc_url)
logging.info("Loading koji component list")
components = [comp["package_name"] for comp in session.listPackages(tagID=tag.id, inherited=True)]

if not cmdline.component is None:
    if not cmdline.component in components:
        logging.error("Failed to find {0} in koji {1} tag.".format(cmdline.component, cmdline.tag))
        exit(1)
    components = [cmdline.component]

skip_build_id_list = []
if cmdline.only_missing:
    skip = db.session.query(Build.secondary_id) \
                     .join(OpSysComponent) \
                     .join(OpSys) \
                     .filter(Opsys.id == opsys.id) \
                     .all()
    skip_build_id_list = [s[0] for s in skip]

i = 0
for component in sorted(components):
    i += 1
    logging.info("[{0}/{1}] Processing component {2}".format(i, len(components), component))
    remote_build = None
    for tag in tags:
        logging.debug("Trying tag {0}".format(tag.name))
        remote_builds = session.listTagged(tag.name, package=component)
        if remote_builds:
            logging.info("Found in {0}".format(tag.name))
            remote_build = remote_builds[0]
            break

    if not remote_build:
        logging.info("Unable to find a build")
        continue

    if remote_build["build_id"] in skip_build_id_list:
        logging.info("Skipping existing build #{0}".format(remote_build["build_id"]))
        continue

    try:
        db_component = db.session.query(OpSysComponent).filter(OpSysComponent.name == component).one()
    except NoResultFound:
        logging.error("Unable to find component '{0}'".format(component))
        continue

    if remote_build["epoch"] is None:
        remote_build["epoch"] = 0

    new = Build()
    new.id = None
    new.secondary_id = remote_build["build_id"]
    new.component_id = db_component.id
    new.epoch = remote_build["epoch"]
    new.version = remote_build["version"]
    new.release = remote_build["release"]
    new.projrelease = None
    db.session.add(new)
    # flush to obtain id
    db.session.flush()

    build_id = new.id
    logging.debug("Created new build #{0}".format(build_id))

    buildtags = [tag["name"] for tag in session.listTags(remote_build["build_id"])]
    for tagname in buildtags:
        logging.debug("Adding tag {0} to build #{1}".format(tagname, build_id))
        tag_id = db.session.query(Tag.id).filter(Tag.name == tagname).one()[0]
        new = BuildTag()
        new.build_id = build_id
        new.tag_id = tag_id
        db.session.add(new)
    db.session.flush()

    rpms = session.listBuildRPMs(remote_build["build_id"])
    archs = set([pkg["arch"] for pkg in rpms])
    # src has no logs
    if "src" in archs:
        archs.remove("src")

    # noarch only has logs if it there are no binary packages
    # binary packages may have noarch sub-packages
    if len(archs) > 1 and "noarch" in archs:
        archs.remove("noarch")

    logging.info("Downloading log files")
    for arch in archs:
        logging.debug("Adding architecture {0} to build #{1}".format(arch, build_id))
        arch_id = db.session.query(Arch.id).filter(Arch.name == arch).one()[0]
        new = BuildArch()
        new.build_id = build_id
        new.arch_id = arch_id
        db.session.add(new)
        # flush to obtain id
        db.session.flush()

        download_logs(new, remote_build, buildsys.package_url)

    if cmdline.with_rpms:
        logging.info("Downloading RPMs")
        for pkg in rpms:
            logging.debug("Downloading {0}.{1}".format(pkg["nvr"], pkg["arch"]))
            download_rpm(db, pkg, remote_build, buildsys.package_url, build_id=build_id)
